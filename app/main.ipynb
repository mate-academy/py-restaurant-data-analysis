{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T17:05:08.739537198Z",
     "start_time": "2023-05-18T17:05:07.763645799Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 0\n",
    "Data extraction: get the data from 3 tables & combine it into single `.csv` file.\n",
    "After that read this file using pandas to create Dataframe.\n",
    "So it will be all joined data in 1 dataframe. Quick check - should be 74818 rows in it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT *\nFROM restaurant_order AS ro\nJOIN restaurant_orderitem AS roi ON ro.id = roi.order_id\nJOIN restaurant_product AS rp ON roi.product_id = rp.id\n': no such table: restaurant_order",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "File \u001B[0;32m~/py-restaurant-data-analysis/venv/lib/python3.11/site-packages/pandas/io/sql.py:2200\u001B[0m, in \u001B[0;36mSQLiteDatabase.execute\u001B[0;34m(self, sql, params)\u001B[0m\n\u001B[1;32m   2199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 2200\u001B[0m     \u001B[43mcur\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cur\n",
      "\u001B[0;31mOperationalError\u001B[0m: no such table: restaurant_order",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mDatabaseError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m conn \u001B[38;5;241m=\u001B[39m sqlite3\u001B[38;5;241m.\u001B[39mconnect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdb.sqlite3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124mSELECT *\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124mFROM restaurant_order AS ro\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124mJOIN restaurant_orderitem AS roi ON ro.id = roi.order_id\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124mJOIN restaurant_product AS rp ON roi.product_id = rp.id\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m---> 10\u001B[0m combined_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m conn\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m     14\u001B[0m combined_df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrestaurant.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/py-restaurant-data-analysis/venv/lib/python3.11/site-packages/pandas/io/sql.py:467\u001B[0m, in \u001B[0;36mread_sql_query\u001B[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[1;32m    464\u001B[0m     dtype_backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pandasSQL_builder(con) \u001B[38;5;28;01mas\u001B[39;00m pandas_sql:\n\u001B[0;32m--> 467\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[43m        \u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    469\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/py-restaurant-data-analysis/venv/lib/python3.11/site-packages/pandas/io/sql.py:2264\u001B[0m, in \u001B[0;36mSQLiteDatabase.read_query\u001B[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[1;32m   2253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_query\u001B[39m(\n\u001B[1;32m   2254\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   2255\u001B[0m     sql,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2262\u001B[0m     dtype_backend: DtypeBackend \u001B[38;5;241m|\u001B[39m Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2263\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Iterator[DataFrame]:\n\u001B[0;32m-> 2264\u001B[0m     cursor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2265\u001B[0m     columns \u001B[38;5;241m=\u001B[39m [col_desc[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m col_desc \u001B[38;5;129;01min\u001B[39;00m cursor\u001B[38;5;241m.\u001B[39mdescription]\n\u001B[1;32m   2267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/py-restaurant-data-analysis/venv/lib/python3.11/site-packages/pandas/io/sql.py:2212\u001B[0m, in \u001B[0;36mSQLiteDatabase.execute\u001B[0;34m(self, sql, params)\u001B[0m\n\u001B[1;32m   2209\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ex \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01minner_exc\u001B[39;00m\n\u001B[1;32m   2211\u001B[0m ex \u001B[38;5;241m=\u001B[39m DatabaseError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecution failed on sql \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msql\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2212\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ex \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[0;31mDatabaseError\u001B[0m: Execution failed on sql '\nSELECT *\nFROM restaurant_order AS ro\nJOIN restaurant_orderitem AS roi ON ro.id = roi.order_id\nJOIN restaurant_product AS rp ON roi.product_id = rp.id\n': no such table: restaurant_order"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"db.sqlite3\")\n",
    "\n",
    "query = '''\n",
    "SELECT *\n",
    "FROM restaurant_order AS ro\n",
    "JOIN restaurant_orderitem AS roi ON ro.id = roi.order_id\n",
    "JOIN restaurant_product AS rp ON roi.product_id = rp.id\n",
    "'''\n",
    "\n",
    "combined_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "combined_df.to_csv(\"restaurant.csv\", index=False)\n",
    "\n",
    "restaurant_order = pd.read_csv(\"restaurant.csv\")\n",
    "df = pd.DataFrame(restaurant_order)\n",
    "\n",
    "print(len(restaurant_order))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T17:05:09.040500159Z",
     "start_time": "2023-05-18T17:05:08.741869113Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1\n",
    "Get Top 10 most popular products in restaurant sold by Quantity.\n",
    "Count how many times each product was sold and create a pie chart with percentage of popularity (by quantity) for top 10 of them.\n",
    "\n",
    "Example:\n",
    "\n",
    "![pie chart](../demo/pie.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "product_sales = df.groupby(\"name\")[\"quantity\"].sum().reset_index()\n",
    "\n",
    "top_10_products = product_sales.nlargest(10, \"quantity\")\n",
    "\n",
    "top_10_products[\"popularity_percentage\"] = (top_10_products[\"quantity\"] / top_10_products[\"quantity\"].sum()) * 100\n",
    "\n",
    "labels = top_10_products[\"name\"]\n",
    "sizes = top_10_products[\"popularity_percentage\"]\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\")\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Top 10 Most Popular Products by Quantity\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2\n",
    "Calculate `Item Price` (Product Price * Quantity) for each Order Item in dataframe.\n",
    "And Make the same Top 10 pie chart, but this time by `Item Price`. So this chart should describe not the most popular products by quantity, but which products (top 10) make the most money for restaurant. It should be also with percentage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"item_price\"] = df[\"price\"] * df[\"quantity\"]\n",
    "\n",
    "\n",
    "product_sales = df.groupby(\"name\")[\"item_price\"].sum().reset_index()\n",
    "\n",
    "\n",
    "top_10_products = product_sales.nlargest(10, \"item_price\")\n",
    "\n",
    "top_10_products[\"revenue_percentage\"] = (top_10_products[\"item_price\"] / top_10_products[\"item_price\"].sum()) * 100\n",
    "\n",
    "labels = top_10_products[\"name\"]\n",
    "sizes = top_10_products[\"revenue_percentage\"]\n",
    "plt.pie(sizes, labels=labels, autopct=\"%1.1f%%\")\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Top 10 Products Generating Highest Revenue\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " # Task 3\n",
    "Calculate `Order Hour` based on `Order Datetime`, which will tell about the specific our the order was created (from 0 to 23). Using `Order Hour` create a bar chart, which will tell the total restaurant income based on the hour order was created. So on x-axis - it will be values from 0 to 23 (hours), on y-axis - it will be the total sum of order prices, which were sold on that hour.\n",
    "\n",
    "Example:\n",
    "\n",
    "![bar chart](../demo/bar.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "hourly_income = df.groupby(\"hour\")[\"quantity\"].sum().reset_index()\n",
    "\n",
    "plt.bar(hourly_income.hour, hourly_income.quantity)\n",
    "plt.xlabel(\"Order Hour\")\n",
    "plt.ylabel(\"Total Sum of Order Prices\")\n",
    "plt.title(\"Restaurant Income by Order Hour\")\n",
    "plt.xticks(range(1, 23))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 4\n",
    "Make similar bar chart, but right now with `Order Day Of The Week` (from Monday to Sunday), and also analyze total restaurant income by each day of the week."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df[\"day\"] = df[\"timestamp\"].dt.day_name()\n",
    "daily_income = df.groupby(\"day\")[\"quantity\"].sum().reset_index()\n",
    "\n",
    "sort_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "daily_income = daily_income.sort_values(by=\"day\", key=lambda x: pd.Categorical(x, categories=sort_order))\n",
    "\n",
    "\n",
    "plt.bar(daily_income.day, daily_income.quantity)\n",
    "plt.xlabel(\"Order day\")\n",
    "plt.ylabel(\"Total Sum of Order Prices\")\n",
    "plt.title(\"Restaurant Income by Order Day\")\n",
    "plt.xticks(range(7), daily_income.day)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, the highest income during the week occurs on the weekends, especially on Friday and Saturday. However, the income levels are relatively average on working days.\n"
     ]
    }
   ],
   "source": [
    "print(\"Finally, the highest income during the week occurs on the weekends, especially on Friday and Saturday. However, the income levels are relatively average on working days.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T20:42:05.039802340Z",
     "start_time": "2023-05-17T20:42:05.037048133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-17T20:42:05.044918097Z",
     "start_time": "2023-05-17T20:42:05.041165376Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
